# 模型配置

# === 模型提供者設定 ===
# provider.type 選項：
#   - local: 本機載入 Transformers 模型（需要 GPU/CPU 資源）
#   - openai: OpenAI 相容 API（支援 vLLM、Ollama、OpenAI、LM Studio 等）
#   - huggingface: Hugging Face Inference Endpoint
provider:
  type: "local"  # 目前使用本機載入

  # Local Provider 設定
  local:
    name: "TAIDE-LX-7B"
    path: "models/models--taide--TAIDE-LX-7B/snapshots/099c425ede93588d7df6e5279bd6b03f1371c979"
    force_cpu: false
    max_gpu_memory: 8
    quantization:
      enable_4bit: true
      load_in_4bit: true
      offload:
        device_map: "auto"
        offload_folder: "./offload"

  # # === OpenAI 相容 API 設定（當 type=openai 時使用）===
  # # 使用方式：先部署推論服務（vLLM/Ollama/LM Studio），再設定以下參數
  # openai:
  #   # API Base URL
  #   # - vLLM: http://localhost:8000/v1
  #   # - Ollama: http://localhost:11434/v1
  #   # - OpenAI: https://api.openai.com/v1
  #   api_base: "http://localhost:8000/v1"
  #   # API Key（選填，某些本地部署不需要）
  #   api_key: null
  #   # 模型名稱（須與 API 端點的模型名稱對應）
  #   model: "taide/TAIDE-LX-7B"
  #   # 請求逾時（秒）
  #   timeout: 120
  #   # 最大重試次數
  #   max_retries: 2

  # # === Hugging Face Inference Endpoint 設定（當 type=huggingface 時使用）===
  # # 使用方式：在 HF 建立 Inference Endpoint，取得 URL 與 Token
  # huggingface:
  #   # Inference Endpoint URL（從 HF 控制台取得）
  #   endpoint_url: "https://your-endpoint.endpoints.huggingface.cloud"
  #   # Hugging Face API Token（必填，從 HF Settings → Access Tokens 取得）
  #   api_token: "hf_your_token_here"
  #   # 請求逾時（秒）
  #   timeout: 120
  #   # 最大重試次數
  #   max_retries: 2

# 生成參數設定
generation:
  # 快速模式參數
  fast:
    temperature: 0.4   # 降低以提升穩定性（原 0.7）
    top_p: 0.85        # 降低以減少隨機性（原 0.9）
    num_beams: 1
    do_sample: true
    min_new_tokens: 5  # 提高到 5，避免提早結束（原 1）
    max_new_tokens: 256
    max_tokens: 256
    repetition_penalty: 1.2  # 降低避免過度懲罰（原 1.5）
    no_repeat_ngram_size: 3
  
  # 標準模式參數
  standard:
    temperature: 0.3  # 降低以提升穩定性（原 0.5）
    top_p: 0.85
    num_beams: 1
    do_sample: true
    min_new_tokens: 10  # 提高到 10，確保生成足夠內容（原 5）
    max_new_tokens: 512
    max_tokens: 512
    repetition_penalty: 1.2  # 降低避免過度懲罰（原 1.5）
    no_repeat_ngram_size: 3
  
  # 高品質模式參數
  high:
    temperature: 0.2
    top_p: 0.8
    num_beams: 4
    do_sample: false
    min_new_tokens: 10  # 提高到 10，確保生成品質（原 1）
    max_new_tokens: 1024
    max_tokens: 1024
    repetition_penalty: 1.2  # 降低避免過度懲罰（原 1.5）
    no_repeat_ngram_size: 3

# Prompt 範本
prompts:
  # 翻譯 Prompt 範本 - 使用 TAIDE/Llama [INST] 格式
  translation: |
    [INST] 你是專業翻譯員。請將以下{source_language}文字翻譯成{target_language}。只輸出翻譯結果，不要輸出原文，不要解釋，不要續寫。

    {text} [/INST]
  
  # 語言偵測 Prompt 範本
  language_detection: |
    [INST] 請識別以下文字的語言，只回答語言代碼（zh-TW, zh-CN, en, ja, ko, fr, de, es 其中之一）和信心分數（0.0-1.0），格式為「語言代碼:信心分數」。

    文字：{text} [/INST]
