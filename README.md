# å¤šåœ‹èªè¨€ç¿»è­¯ç³»çµ±

åŸºæ–¼ TAIDE-LX-7B å¤§å‹èªè¨€æ¨¡å‹çš„å¤šåœ‹èªè¨€ç¿»è­¯ç³»çµ±ï¼Œæ¡ç”¨ Django ASGI + HTMX + Alpine.js æŠ€è¡“æ¶æ§‹ï¼Œæä¾›å³æ™‚ç¿»è­¯ã€æ­·å²è¨˜éŒ„ã€ä½¿ç”¨è€…è¨­å®šç­‰åŠŸèƒ½ã€‚

## åŠŸèƒ½ç‰¹é»

- ğŸŒ **å¤šèªè¨€æ”¯æ´**ï¼šæ”¯æ´ç¹é«”ä¸­æ–‡ã€ç°¡é«”ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ“æ–‡ã€è¶Šå—æ–‡ã€æ³°æ–‡ã€å°å°¼æ–‡ç­‰ 8 ç¨®èªè¨€
- ğŸ”„ **è‡ªå‹•èªè¨€åµæ¸¬**ï¼šæ™ºæ…§åµæ¸¬è¼¸å…¥æ–‡å­—çš„ä¾†æºèªè¨€
- âš¡ **å³æ™‚ç¿»è­¯**ï¼šä½å»¶é²ç¿»è­¯å›æ‡‰ï¼Œæ”¯æ´ GPU åŠ é€Ÿ
- ğŸ“ **ç¿»è­¯æ­·å²**ï¼šç€è¦½å™¨æœ¬åœ°å„²å­˜ï¼Œä¿ç•™æœ€è¿‘ 20 ç­†ç¿»è­¯è¨˜éŒ„
- âš™ï¸ **å€‹äººåŒ–è¨­å®š**ï¼šæ”¯æ´æ·±è‰²/æ·ºè‰²ä¸»é¡Œã€å­—é«”å¤§å°èª¿æ•´
- ğŸ“Š **ç³»çµ±ç›£æ§**ï¼šå³æ™‚æŸ¥çœ‹ç³»çµ±è³‡æºä½¿ç”¨ç‹€æ³å’Œç¿»è­¯çµ±è¨ˆ

## ç³»çµ±éœ€æ±‚

### ç¡¬é«”éœ€æ±‚

| é …ç›®   | æœ€ä½éœ€æ±‚ | å»ºè­°é…ç½®                |
| ------ | -------- | ----------------------- |
| CPU    | 4 æ ¸å¿ƒ   | 8 æ ¸å¿ƒä»¥ä¸Š              |
| è¨˜æ†¶é«” | 16 GB    | 32 GB ä»¥ä¸Š              |
| GPU    | -        | NVIDIA GPU (16GB+ VRAM) |
| ç£ç¢Ÿ   | 50 GB    | 100 GB SSD              |

### è»Ÿé«”éœ€æ±‚

- Python 3.11ï¼ˆæ¨è–¦ï¼›Windows ä¸Šå‹™å¿…ä½¿ç”¨ 3.11 ä»¥ç¢ºä¿ PyTorch cu118 ç›¸å®¹æ€§ï¼Œä½†è‹¥ç³»çµ±æœ‰ 3.10 ä¹Ÿå¯ä»¥ï¼‰
- CUDA 11.8+ï¼ˆGPU åŠ é€Ÿæ™‚éœ€è¦ï¼‰
- Git

## å¿«é€Ÿé–‹å§‹

### 1. è¤‡è£½å°ˆæ¡ˆ

```bash
git clone <repository-url>
cd MutilLanguageTranslate
```

### 2. å»ºç«‹è™›æ“¬ç’°å¢ƒ

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/macOS
source venv/bin/activate
```

### 3. å®‰è£ç›¸ä¾å¥—ä»¶

#### CPU æ¨¡å¼ï¼ˆæˆ–å·²å®‰è£ PyTorchï¼‰

```bash
pip install -r requirements.txt
```

#### GPU æ¨¡å¼ï¼ˆNVIDIA CUDAï¼‰

**é‡è¦ï¼š** è«‹ä½¿ç”¨ Python 3.10 æˆ– 3.11ï¼ˆPyTorch cu118 wheel æ”¯æ´é€™äº›ç‰ˆæœ¬ï¼‰ã€‚

```powershell
# å‡ç´š pip
pip install --upgrade pip

# 1. å®‰è£ PyTorch with CUDA 11.8
pip install --index-url https://download.pytorch.org/whl/cu118 torch torchvision

# 2. å®‰è£å°ˆæ¡ˆç›¸ä¾å¥—ä»¶
pip install -r requirements.txt

# 3. (å¯é¸) å®‰è£ bitsandbytes ä»¥å•Ÿç”¨ 4-bit é‡åŒ–ï¼ˆé©ç”¨æ–¼ 8GB VRAM ä»¥ä¸‹çš„ GPUï¼‰
# Windows ä¸Šå¯èƒ½éœ€è¦ Visual Studio Build Tools
pip install bitsandbytes
```

**ç–‘é›£æ’è§£ï¼š**
- è‹¥ Python ç‰ˆæœ¬ç‚º 3.14 ç­‰è¼ƒæ–°ç‰ˆæœ¬ï¼ŒPyTorch å®˜æ–¹ wheel å¯èƒ½å°šæœªæ”¯æ´ï¼Œè«‹ä½¿ç”¨ `py -3.10` æˆ– `py -3.11` å»ºç«‹è™›æ“¬ç’°å¢ƒã€‚
- bitsandbytes åœ¨ Windows ä¸Šå¯èƒ½éœ€è¦ç·¨è­¯å·¥å…·ï¼Œè‹¥å®‰è£å¤±æ•—å¯è·³éï¼ˆç³»çµ±æœƒè‡ªå‹•ä½¿ç”¨ float16 æ¨¡å¼ï¼‰ã€‚

### 4. è¨­å®šé…ç½®æª”

```bash
# è¤‡è£½ç¯„ä¾‹é…ç½®æª”
cp config/app_config.yaml.example config/app_config.yaml
cp config/model_config.yaml.example config/model_config.yaml

# ä¾æ“šéœ€æ±‚ç·¨è¼¯é…ç½®æª”
```

### 5. ä¸‹è¼‰æ¨¡å‹

æ¨¡å‹æœƒåœ¨é¦–æ¬¡å•Ÿå‹•æ™‚è‡ªå‹•ä¸‹è¼‰ï¼Œæˆ–å¯æ‰‹å‹•ä¸‹è¼‰ï¼š

```bash
# æ¨¡å‹å°‡å„²å­˜æ–¼ models/ ç›®éŒ„
python -c "from transformers import AutoModelForCausalLM; AutoModelForCausalLM.from_pretrained('taide/TAIDE-LX-7B', cache_dir='./models')"
```

### 6. å•Ÿå‹•æœå‹™

```bash
cd translation_project

# é–‹ç™¼æ¨¡å¼
..\.venv\Scripts\python manage.py runserver

# ç”Ÿç”¢æ¨¡å¼ï¼ˆä½¿ç”¨ uvicornï¼‰
uvicorn translation_project.asgi:application --host 0.0.0.0 --port 8000
```

### 7. é–‹å•Ÿç€è¦½å™¨

é€ è¨ª http://localhost:8000 é–‹å§‹ä½¿ç”¨ç¿»è­¯æœå‹™ã€‚

## GPU è¨˜æ†¶é«”æœ€ä½³åŒ–ï¼ˆè‡ªå‹•åµæ¸¬ï¼‰

ç³»çµ±æœƒ**è‡ªå‹•åµæ¸¬** GPU è¨˜æ†¶é«”å¤§å°ä¸¦é¸æ“‡æœ€ä½³è¼‰å…¥æ¨¡å¼ï¼š

- **VRAM â‰¤ 12GB**ï¼ˆä¾‹å¦‚ RTX 4060 8GB, RTX 3060 12GBï¼‰ï¼šè‡ªå‹•å•Ÿç”¨ **4-bit é‡åŒ–**ï¼Œç¯€çœ 70-75% è¨˜æ†¶é«”
- **VRAM > 12GB**ï¼ˆä¾‹å¦‚ RTX 4090 24GBï¼‰ï¼šä½¿ç”¨ **float16 æ¨¡å¼**ï¼Œä¿æŒæœ€ä½³å“è³ª

ç„¡éœ€æ‰‹å‹•è¨­å®šï¼Œç³»çµ±æœƒè‡ªå‹•é¸æ“‡æœ€é©åˆçš„æ¨¡å¼ã€‚

### æ‰‹å‹•è¦–ç›–è‡ªå‹•åµæ¸¬ï¼ˆå¯é¸ï¼‰

è‹¥æ‚¨æƒ³å¼·åˆ¶ä½¿ç”¨ç‰¹å®šæ¨¡å¼ï¼Œå¯ä¿®æ”¹ `config/model_config.yaml`ï¼š

```yaml
# å¼·åˆ¶å•Ÿç”¨ 4-bit é‡åŒ–ï¼ˆå¿½ç•¥è‡ªå‹•åµæ¸¬ï¼‰
quantization:
  enable_4bit: true
  load_in_4bit: true

# æˆ–å¼·åˆ¶åœç”¨ 4-bit é‡åŒ–ï¼ˆä½¿ç”¨ float16ï¼‰
quantization:
  enable_4bit: false
```

### bitsandbytes å®‰è£èªªæ˜

4-bit é‡åŒ–éœ€è¦ `bitsandbytes` å¥—ä»¶ï¼ˆå·²åŒ…å«åœ¨ `requirements.txt` ä¸­ï¼‰ï¼š

- **Linux**: ç›´æ¥å®‰è£å³å¯
- **Windows**: å¯èƒ½éœ€è¦ [Visual Studio Build Tools](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2022)ï¼ˆC++ é–‹ç™¼å·¥å…·ï¼‰

è‹¥ bitsandbytes å®‰è£å¤±æ•—æˆ–ä¸å¯ç”¨ï¼Œç³»çµ±æœƒè‡ªå‹•é€€å›ä½¿ç”¨ float16 æ¨¡å¼ã€‚

### æ–¹æ³• 2ï¼šCPU/GPU Offloadï¼ˆaccelerateï¼‰

ä½¿ç”¨ `accelerate` å°‡æ¨¡å‹éƒ¨åˆ†å±¤ç§»è‡³ CPU æˆ–ç£ç¢Ÿï¼Œä»¥é©é… GPU è¨˜æ†¶é«”é™åˆ¶ã€‚

```powershell
# accelerate å·²åœ¨ requirements.txt ä¸­ï¼Œç¢ºèªå·²å®‰è£
pip install accelerate
```

`config/model_config.yaml` ä¸­è¨­å®š `max_gpu_memory` ç‚ºæ‚¨çš„ VRAM å¤§å°ï¼š

```yaml
model:
  max_gpu_memory: 8  # 8GB VRAM
```

ç³»çµ±æœƒè‡ªå‹•ä½¿ç”¨ `device_map="auto"` å°‡æ¨¡å‹å±¤åˆ†é…åˆ° GPU/CPU/ç£ç¢Ÿã€‚

### æ¸¬è©¦è¨­å®š

æ‚¨å¯ä»¥ä½¿ç”¨å…§å»ºçš„æ¸¬è©¦ API é©—è­‰è¨­å®šæ˜¯å¦æ­£ç¢ºï¼š

```powershell
# æ¸¬è©¦è¼‰å…¥å°æ¨¡å‹ï¼ˆgpt2ï¼‰ä»¥é©—è­‰ GPU èˆ‡é‡åŒ–è¨­å®š
curl -X POST http://localhost:8000/api/v1/admin/model/test/ -H "Content-Type: application/json" -d '{"model_name": "gpt2"}'
```

æˆ–ä½¿ç”¨æˆ‘å€‘æä¾›çš„æ¸¬è©¦è…³æœ¬ï¼š

```powershell
.venv\Scripts\python tests\quick_model_test.py
```

### 7. é–‹å•Ÿç€è¦½å™¨

é€ è¨ª http://localhost:8000 é–‹å§‹ä½¿ç”¨ç¿»è­¯æœå‹™ã€‚

## å®¹å™¨éƒ¨ç½²ï¼ˆPodman / Docker / Composeï¼‰

> é©—è­‰é‡é»ï¼šæœå‹™å•Ÿå‹•å¾Œ `GET /api/health/` éœ€å› 200ã€‚

### ä½¿ç”¨ Podman

```bash
# å»ºç½®æ˜ åƒ
podman build -t translation-service -f Containerfile .

# åŸ·è¡Œå®¹å™¨
podman run -d \
  --name translation-service \
  -p 8000:8000 \
  -v ./models:/app/models:ro \
  -v ./config:/app/config:ro \
  -v ./logs:/app/logs \
  translation-service
```

### ä½¿ç”¨ Docker

```bash
docker build -t translation-service -f Containerfile .

docker run -d \
  --name translation-service \
  -p 8000:8000 \
  -v ./models:/app/models:ro \
  -v ./config:/app/config:ro \
  -v ./logs:/app/logs \
  translation-service
```

### ä½¿ç”¨ Docker Compose

```bash
docker compose -f docker-compose.yaml up -d
```

### å¥åº·æª¢æŸ¥

```bash
curl -f http://localhost:8000/api/health/
```

## ç›®éŒ„çµæ§‹

```
MutilLanguageTranslate/
â”œâ”€â”€ config/                          # é…ç½®æª”ç›®éŒ„
â”‚   â”œâ”€â”€ app_config.yaml              # æ‡‰ç”¨ç¨‹å¼é…ç½®
â”‚   â”œâ”€â”€ model_config.yaml            # æ¨¡å‹é…ç½®
â”‚   â””â”€â”€ languages.yaml               # èªè¨€å®šç¾©
â”œâ”€â”€ logs/                            # æ—¥èªŒç›®éŒ„
â”œâ”€â”€ models/                          # æ¨¡å‹ç›®éŒ„
â”‚   â”œâ”€â”€ TAIDE-LX-7B-Chat/            # æ¨¡å‹åç¨±ä¸€
â”‚   â””â”€â”€ Llama-3.1-TAIDE-LX-8B-Chat/  # æ¨¡å‹åç¨±ä¸€
â”œâ”€â”€ translation_project/             # Django å°ˆæ¡ˆ
â”‚   â”œâ”€â”€ translation_project/         # å°ˆæ¡ˆè¨­å®š
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ asgi.py
â”‚   â””â”€â”€ translator/                  # ç¿»è­¯æ‡‰ç”¨ç¨‹å¼
â”‚       â”œâ”€â”€ api/                     # REST API
â”‚       â”œâ”€â”€ services/                # æœå‹™å±¤
â”‚       â”œâ”€â”€ templates/               # å‰ç«¯æ¨¡æ¿
â”‚       â”œâ”€â”€ static/                  # éœæ…‹è³‡æº
â”‚       â””â”€â”€ utils/                   # å·¥å…·å‡½æ•¸
â”œâ”€â”€ specs/                           # è¦æ ¼æ–‡ä»¶
â”œâ”€â”€ tests/                           # æ¸¬è©¦
â”œâ”€â”€ Containerfile                    # å®¹å™¨å»ºç½®æª”
â”œâ”€â”€ docker-compose.yaml              # Docker Compose
â”œâ”€â”€ requirements.txt                 # Python ç›¸ä¾å¥—ä»¶
â””â”€â”€ README.md                        # æœ¬æ–‡ä»¶
```

## API æ–‡ä»¶

### ç¿»è­¯ API

#### POST /api/v1/translate/

åŸ·è¡Œæ–‡å­—ç¿»è­¯ã€‚

**è«‹æ±‚**
```json
{
  "text": "è¦ç¿»è­¯çš„æ–‡å­—",
  "source_language": "auto",
  "target_language": "en",
  "quality": "standard"
}
```

**å›æ‡‰**
```json
{
  "request_id": "uuid",
  "status": "completed",
  "translated_text": "Translated text",
  "processing_time_ms": 1234.56,
  "detected_language": "zh-TW"
}
```

### å¥åº·æª¢æŸ¥ API

#### GET /api/health/

å›å‚³ç³»çµ±å¥åº·ç‹€æ…‹ã€‚

#### GET /api/ready/

å°±ç·’æ¢é‡ï¼Œæª¢æŸ¥æœå‹™æ˜¯å¦æº–å‚™å¥½æ¥æ”¶æµé‡ã€‚

#### GET /api/live/

å­˜æ´»æ¢é‡ï¼Œæª¢æŸ¥æœå‹™æ˜¯å¦å­˜æ´»ã€‚

### èªè¨€ API

#### GET /api/v1/languages/

å–å¾—æ”¯æ´çš„èªè¨€æ¸…å–®ã€‚

### ç®¡ç† API

#### POST /api/v1/admin/model/test/

æ¸¬è©¦è¼‰å…¥å°å‹æ¨¡å‹ï¼ˆç”¨æ–¼é©—è­‰ç’°å¢ƒèˆ‡é‡åŒ–è¨­å®šï¼‰ã€‚

**è«‹æ±‚**
```json
{
  "model_name": "gpt2"
}
```

**å›æ‡‰**
```json
{
  "success": true,
  "message": "å°æ¨¡å‹è¼‰å…¥èˆ‡æ¨è«–æˆåŠŸ (gpt2)",
  "model_info": {
    "model_name": "gpt2",
    "generated": "Hello world, I'm not sure what to say",
    "cuda_available": true,
    "cuda_device_count": 1
  }
}
```

## é…ç½®èªªæ˜

### app_config.yaml

```yaml
server:
  host: "0.0.0.0"
  port: 8000
  workers: 1

translation:
  default_source_language: "auto"
  default_target_language: "en"
  max_text_length: 5000
  timeout_seconds: 120

security:
  admin_ip_whitelist:
    - "127.0.0.1"
    - "::1"
```

### model_config.yaml

```yaml
model:
  name: "taide/TAIDE-LX-7B"
  cache_dir: "./models"
  device: "auto"  # auto, cuda, cpu
  torch_dtype: "auto"

inference:
  max_new_tokens: 2048
  temperature: 0.7
  top_p: 0.9
```

## ç•Œé¢ç¯„ä¾‹

![](./Docs/images/Interfase.png)
![](./Docs/images/History.png)
![](./Docs/images/Setting.png)

## æˆæ¬Š

MIT License

## è²¢ç»

æ­¡è¿æäº¤ Issue å’Œ Pull Requestï¼

## è¯çµ¡

å¦‚æœ‰å•é¡Œï¼Œè«‹é€é GitHub Issues è¯çµ¡æˆ‘å€‘ã€‚
