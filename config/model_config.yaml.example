# 模型配置範例
# 複製為 model_config.yaml 並根據需求調整

# === 模型提供者設定 ===
# provider.type 選項：
#   - local: 本機載入 Transformers 模型（需要 GPU/CPU 資源）
#   - openai: OpenAI 相容 API（支援 vLLM、Ollama、OpenAI、LM Studio 等）
#   - huggingface: Hugging Face Inference Endpoint
provider:
  type: "local"  # 預設：本機載入

  # === Local Provider 設定（當 type=local 時使用）===
  local:
    # 模型名稱
    name: "TAIDE-LX-7B"
    # 模型路徑（相對於專案根目錄）
    path: "models/models--taide--TAIDE-LX-7B/snapshots/099c425ede93588d7df6e5279bd6b03f1371c979"
    # 強制使用 CPU（即使有 GPU 可用）
    force_cpu: false
    # GPU 記憶體上限 (GiB)，null 表示無限制
    max_gpu_memory: 8
    # 量化與 offload 選項（針對 VRAM 受限的 GPU）
    quantization:
      # 啟用 4-bit 量化（需安裝 bitsandbytes）
      enable_4bit: true
      load_in_4bit: true
      offload:
        device_map: "auto"
        offload_folder: "./offload"

  # === OpenAI 相容 API 設定（當 type=openai 時使用）===
  # 使用方式：先部署推論服務（vLLM/Ollama/LM Studio），再設定以下參數
  openai:
    # API Base URL
    # - vLLM: http://localhost:8000/v1
    # - Ollama: http://localhost:11434/v1
    # - OpenAI: https://api.openai.com/v1
    api_base: "http://localhost:8000/v1"
    # API Key（選填，某些本地部署不需要）
    api_key: null
    # 模型名稱（須與 API 端點的模型名稱對應）
    model: "taide/TAIDE-LX-7B"
    # 請求逾時（秒）
    timeout: 120
    # 最大重試次數
    max_retries: 2

  # === Hugging Face Inference Endpoint 設定（當 type=huggingface 時使用）===
  # 使用方式：在 HF 建立 Inference Endpoint，取得 URL 與 Token
  huggingface:
    # Inference Endpoint URL（從 HF 控制台取得）
    endpoint_url: "https://your-endpoint.endpoints.huggingface.cloud"
    # Hugging Face API Token（必填，從 HF Settings → Access Tokens 取得）
    api_token: "hf_your_token_here"
    # 請求逾時（秒）
    timeout: 120
    # 最大重試次數
    max_retries: 2

# 生成參數設定（適用於所有 provider）
generation:
  # 快速模式參數
  fast:
    temperature: 0.7
    top_p: 0.9
    max_tokens: 256          # 遠端 API 使用
    max_new_tokens: 256      # 本地模式使用
    num_beams: 1             # 本地模式專用
    do_sample: true          # 本地模式專用
    min_new_tokens: 1        # 本地模式專用
    repetition_penalty: 1.5  # 本地模式專用
    no_repeat_ngram_size: 3  # 本地模式專用
  
  # 標準模式參數
  standard:
    temperature: 0.5
    top_p: 0.85
    max_tokens: 512
    max_new_tokens: 512
    num_beams: 1
    do_sample: true
    min_new_tokens: 1
    repetition_penalty: 1.5
    no_repeat_ngram_size: 3
  
  # 高品質模式參數
  high:
    temperature: 0.3
    top_p: 0.8
    max_tokens: 1024
    max_new_tokens: 1024
    num_beams: 4
    do_sample: false
    min_new_tokens: 1
    repetition_penalty: 1.5
    no_repeat_ngram_size: 3

# Prompt 範本
prompts:
  # 翻譯 Prompt 範本 - 使用 TAIDE/Llama [INST] 格式
  translation: |
    [INST] 你是專業翻譯員。請將以下{source_language}文字翻譯成{target_language}。只輸出翻譯結果，不要輸出原文，不要解釋，不要續寫。

    {text} [/INST]
  
  # 語言偵測 Prompt 範本
  language_detection: |
    [INST] 請識別以下文字的語言，只回答語言代碼（zh-TW, zh-CN, en, ja, ko, fr, de, es 其中之一）和信心分數（0.0-1.0），格式為「語言代碼:信心分數」。

    文字：{text} [/INST]
